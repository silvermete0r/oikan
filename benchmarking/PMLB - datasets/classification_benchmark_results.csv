dataset,device,num_features,num_augmented_rows,augmentation_factor,train_time,train_memory,predict_time,predict_memory,accuracy
adult,cpu,14,78146,2,384.07213497161865,374.332458,0.04258227348327637,9.101876,0.7766403930801515
mushroom,cpu,22,64990,10,106.00510931015015,639.678202,0.028440237045288086,1.909308,0.9981538461538462
iris,cpu,4,1200,10,1.2353568077087402,1.590256,0.004458189010620117,0.04557,0.9666666666666667
wine_recognition,cpu,13,1420,10,2.103851795196533,6.281135,0.0033643245697021484,0.0335,0.9166666666666666
tic_tac_toe,cpu,9,7660,10,8.086595296859741,20.502848,0.0019173622131347656,0.075073,0.8333333333333334
analcatdata_authorship,cpu,70,6720,10,140.39503240585327,559.680939,0.04899287223815918,2.116747,1.0
analcatdata_fraud,cpu,11,1023,31,0.6038320064544678,3.640692,0.0010273456573486328,0.003783,0.5555555555555556
penguins,cpu,7,2660,10,2.9871935844421387,5.559306,0.0016016960144042969,0.025793,0.6716417910447762
monk3,cpu,6,4430,10,4.086931228637695,7.95081,0.0013642311096191406,0.024817,0.954954954954955
balance_scale,cpu,4,5000,10,5.2176353931427,6.079827,0.004388093948364258,0.066275,0.96
car_evaluation,cpu,6,13820,10,27.170278072357178,25.074323,0.025125503540039062,0.182348,0.869942196531792
dermatology,cpu,34,2920,10,13.485450267791748,62.501102,0.028313636779785156,0.197276,0.9864864864864865
ionosphere,cpu,34,2800,10,6.1008620262146,59.74228,0.023125171661376953,0.102472,0.9577464788732394
kr_vs_kp,cpu,36,25560,10,88.24426221847534,603.79857,0.016607284545898438,1.163587,0.95625
lymphography,cpu,18,1180,10,2.055842399597168,8.562061,0.008815526962280273,0.058906,0.8666666666666667
