{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17719cdf",
   "metadata": {
    "papermill": {
     "duration": 0.00234,
     "end_time": "2025-04-13T21:02:06.605620",
     "exception": false,
     "start_time": "2025-04-13T21:02:06.603280",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# OIKAN Regression Benchmark Tests\n",
    "\n",
    "This notebook provides comprehensive benchmarking of OIKANRegressor against standard regression models:\n",
    "\n",
    "1. Model Performance:\n",
    "   - MSE, RMSE, MAE, R²\n",
    "   - Training and prediction time\n",
    "   - Model complexity (number of terms)\n",
    "\n",
    "2. Dataset Coverage:\n",
    "   - Synthetic (linear, nonlinear)\n",
    "   - Real-world (diabetes, boston housing)\n",
    "   - Custom physics-based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41b3aadc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T21:02:06.610232Z",
     "iopub.status.busy": "2025-04-13T21:02:06.609965Z",
     "iopub.status.idle": "2025-04-13T21:03:28.141144Z",
     "shell.execute_reply": "2025-04-13T21:03:28.140344Z"
    },
    "papermill": {
     "duration": 81.535393,
     "end_time": "2025-04-13T21:03:28.142813",
     "exception": false,
     "start_time": "2025-04-13T21:02:06.607420",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m77.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "pylibcugraph-cu12 24.12.0 requires pylibraft-cu12==24.12.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\r\n",
      "pylibcugraph-cu12 24.12.0 requires rmm-cu12==24.12.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "!pip install -qU oikan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50f72b1c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T21:03:28.185669Z",
     "iopub.status.busy": "2025-04-13T21:03:28.184967Z",
     "iopub.status.idle": "2025-04-13T21:03:29.899939Z",
     "shell.execute_reply": "2025-04-13T21:03:29.899144Z"
    },
    "papermill": {
     "duration": 1.737826,
     "end_time": "2025-04-13T21:03:29.901539",
     "exception": false,
     "start_time": "2025-04-13T21:03:28.163713",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oikan==0.0.2.5\r\n"
     ]
    }
   ],
   "source": [
    "!pip freeze | grep oikan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a4577c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T21:03:29.944581Z",
     "iopub.status.busy": "2025-04-13T21:03:29.943776Z",
     "iopub.status.idle": "2025-04-13T21:03:37.854491Z",
     "shell.execute_reply": "2025-04-13T21:03:37.853835Z"
    },
    "papermill": {
     "duration": 7.934115,
     "end_time": "2025-04-13T21:03:37.856020",
     "exception": false,
     "start_time": "2025-04-13T21:03:29.921905",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from time import time\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.datasets import make_regression, load_diabetes\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from oikan.model import OIKANRegressor\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f55bfdef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T21:03:37.904933Z",
     "iopub.status.busy": "2025-04-13T21:03:37.903995Z",
     "iopub.status.idle": "2025-04-13T21:03:37.911341Z",
     "shell.execute_reply": "2025-04-13T21:03:37.910674Z"
    },
    "papermill": {
     "duration": 0.032894,
     "end_time": "2025-04-13T21:03:37.912562",
     "exception": false,
     "start_time": "2025-04-13T21:03:37.879668",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_datasets():\n",
    "    datasets = {}\n",
    "    \n",
    "    # 1. Linear synthetic data\n",
    "    X_lin, y_lin = make_regression(n_samples=1000, n_features=10, noise=0.1,\n",
    "                                   random_state=42)\n",
    "    datasets['Linear Synthetic'] = (X_lin, y_lin)\n",
    "    \n",
    "    # 2. Nonlinear synthetic data\n",
    "    X_nonlin = np.random.randn(1000, 10)\n",
    "    y_nonlin = (np.sin(X_nonlin[:, 0]) + np.square(X_nonlin[:, 1]) + \n",
    "                np.exp(X_nonlin[:, 2]/5) + np.tanh(X_nonlin[:, 3]))\n",
    "    datasets['Nonlinear Synthetic'] = (X_nonlin, y_nonlin)\n",
    "    \n",
    "    # 3. Diabetes dataset\n",
    "    X_diabetes, y_diabetes = load_diabetes(return_X_y=True)\n",
    "    datasets['Diabetes'] = (X_diabetes, y_diabetes)\n",
    "    \n",
    "    # 4. Physics-based synthetic\n",
    "    t = np.linspace(0, 10, 1000)\n",
    "    X_phys = np.column_stack([t, np.sin(t), np.cos(t), t**2, np.exp(-t/5)])\n",
    "    y_phys = 2*np.sin(t) + 0.5*t**2 - 0.1*np.exp(-t/5) + np.random.normal(0, 0.1, size=1000)\n",
    "    datasets['Physics'] = (X_phys, y_phys)\n",
    "    \n",
    "    return datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a60eda8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T21:03:37.958892Z",
     "iopub.status.busy": "2025-04-13T21:03:37.958624Z",
     "iopub.status.idle": "2025-04-13T21:03:37.966515Z",
     "shell.execute_reply": "2025-04-13T21:03:37.965963Z"
    },
    "papermill": {
     "duration": 0.032666,
     "end_time": "2025-04-13T21:03:37.967703",
     "exception": false,
     "start_time": "2025-04-13T21:03:37.935037",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def benchmark_model(model, X, y, model_name='OIKAN'):\n",
    "    results = {}\n",
    "    \n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_scaled, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        # Training time\n",
    "        start_time = time()\n",
    "        if model_name == 'OIKAN':\n",
    "            model.fit(X_train, y_train, epochs=100, lr=0.01)\n",
    "        else:\n",
    "            model.fit(X_train, y_train)\n",
    "        train_time = time() - start_time\n",
    "        \n",
    "        # Prediction time\n",
    "        start_time = time()\n",
    "        y_pred = model.predict(X_test)\n",
    "        predict_time = time() - start_time\n",
    "        \n",
    "        # Metrics\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        rmse = np.sqrt(mse)\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        \n",
    "        # Cross-validation score\n",
    "        cv_scores = cross_val_score(model, X_scaled, y, \n",
    "                                   cv=5, scoring='r2')\n",
    "        \n",
    "        results.update({\n",
    "            'Model': model_name,\n",
    "            'MSE': mse,\n",
    "            'RMSE': rmse,\n",
    "            'MAE': mae,\n",
    "            'R2': r2,\n",
    "            'CV R2 Mean': cv_scores.mean(),\n",
    "            'CV R2 Std': cv_scores.std(),\n",
    "            'Train Time': train_time,\n",
    "            'Predict Time': predict_time\n",
    "        })\n",
    "        \n",
    "        # OIKAN-specific metrics\n",
    "        if model_name == 'OIKAN':\n",
    "            # Get symbolic predictions\n",
    "            symbolic_pred = model.symbolic_predict(X_test)\n",
    "            symbolic_mse = mean_squared_error(y_test, symbolic_pred)\n",
    "            symbolic_r2 = r2_score(y_test, symbolic_pred)\n",
    "            \n",
    "            # Get formula and count terms\n",
    "            formula = model.get_symbolic_formula()\n",
    "            n_terms = sum(len(f.split('+')) for f in formula)\n",
    "            \n",
    "            results.update({\n",
    "                'Symbolic MSE': symbolic_mse,\n",
    "                'Symbolic R2': symbolic_r2,\n",
    "                'Formula Terms': n_terms,\n",
    "                'Formula': formula\n",
    "            })\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error benchmarking {model_name}: {str(e)}\")\n",
    "        results = {\n",
    "            'Model': model_name,\n",
    "            'Error': str(e)\n",
    "        }\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e59f9a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T21:03:38.008554Z",
     "iopub.status.busy": "2025-04-13T21:03:38.008363Z",
     "iopub.status.idle": "2025-04-13T21:16:23.720444Z",
     "shell.execute_reply": "2025-04-13T21:16:23.719307Z"
    },
    "papermill": {
     "duration": 765.733552,
     "end_time": "2025-04-13T21:16:23.721880",
     "exception": false,
     "start_time": "2025-04-13T21:03:37.988328",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Benchmarking Linear Synthetic dataset...\n",
      "Testing OIKAN...\n",
      "Epoch [10/100], Loss: 16276.2676\n",
      "Epoch [20/100], Loss: 14477.1758\n",
      "Epoch [30/100], Loss: 12288.1221\n",
      "Epoch [40/100], Loss: 9300.8398\n",
      "Epoch [50/100], Loss: 5956.7285\n",
      "Epoch [60/100], Loss: 3800.5037\n",
      "Epoch [70/100], Loss: 1999.6949\n",
      "Epoch [80/100], Loss: 1296.0496\n",
      "Epoch [90/100], Loss: 810.8312\n",
      "Epoch [100/100], Loss: 644.4294\n",
      "Epoch [10/100], Loss: 17017.0723\n",
      "Epoch [20/100], Loss: 15643.4512\n",
      "Epoch [30/100], Loss: 13924.2871\n",
      "Epoch [40/100], Loss: 11237.7910\n",
      "Epoch [50/100], Loss: 8471.7334\n",
      "Epoch [60/100], Loss: 5336.6484\n",
      "Epoch [70/100], Loss: 2837.8865\n",
      "Epoch [80/100], Loss: 1817.5593\n",
      "Epoch [90/100], Loss: 1143.1967\n",
      "Epoch [100/100], Loss: 756.4972\n",
      "Epoch [10/100], Loss: 16412.0566\n",
      "Epoch [20/100], Loss: 14628.0449\n",
      "Epoch [30/100], Loss: 11947.4043\n",
      "Epoch [40/100], Loss: 9112.9668\n",
      "Epoch [50/100], Loss: 5373.9199\n",
      "Epoch [60/100], Loss: 3029.9766\n",
      "Epoch [70/100], Loss: 1648.5940\n",
      "Epoch [80/100], Loss: 1014.9962\n",
      "Epoch [90/100], Loss: 841.1264\n",
      "Epoch [100/100], Loss: 635.2158\n",
      "Epoch [10/100], Loss: 15772.5830\n",
      "Epoch [20/100], Loss: 13817.1426\n",
      "Epoch [30/100], Loss: 10791.1758\n",
      "Epoch [40/100], Loss: 8013.9580\n",
      "Epoch [50/100], Loss: 5095.1045\n",
      "Epoch [60/100], Loss: 3066.7393\n",
      "Epoch [70/100], Loss: 1509.7164\n",
      "Epoch [80/100], Loss: 863.9948\n",
      "Epoch [90/100], Loss: 764.0291\n",
      "Epoch [100/100], Loss: 727.7850\n",
      "Epoch [10/100], Loss: 16139.0020\n",
      "Epoch [20/100], Loss: 14681.2871\n",
      "Epoch [30/100], Loss: 12282.1143\n",
      "Epoch [40/100], Loss: 9604.3906\n",
      "Epoch [50/100], Loss: 6350.6475\n",
      "Epoch [60/100], Loss: 3835.4824\n",
      "Epoch [70/100], Loss: 1792.6771\n",
      "Epoch [80/100], Loss: 1153.6417\n",
      "Epoch [90/100], Loss: 790.5739\n",
      "Epoch [100/100], Loss: 688.1973\n",
      "Epoch [10/100], Loss: 16786.9102\n",
      "Epoch [20/100], Loss: 15195.9639\n",
      "Epoch [30/100], Loss: 13058.8594\n",
      "Epoch [40/100], Loss: 10061.5752\n",
      "Epoch [50/100], Loss: 7175.4976\n",
      "Epoch [60/100], Loss: 4211.2979\n",
      "Epoch [70/100], Loss: 1802.7784\n",
      "Epoch [80/100], Loss: 1219.7719\n",
      "Epoch [90/100], Loss: 972.6697\n",
      "Epoch [100/100], Loss: 719.4346\n",
      "Testing Linear...\n",
      "Testing Ridge...\n",
      "Testing RandomForest...\n",
      "Testing MLP...\n",
      "\n",
      "Benchmarking Nonlinear Synthetic dataset...\n",
      "Testing OIKAN...\n",
      "Epoch [10/100], Loss: 5759.3638\n",
      "Epoch [20/100], Loss: 1179.3850\n",
      "Epoch [30/100], Loss: 144.0975\n",
      "Epoch [40/100], Loss: 18.4254\n",
      "Epoch [50/100], Loss: 5.9708\n",
      "Epoch [60/100], Loss: 2.9626\n",
      "Epoch [70/100], Loss: 1.6336\n",
      "Epoch [80/100], Loss: 0.9200\n",
      "Epoch [90/100], Loss: 0.5395\n",
      "Epoch [100/100], Loss: 0.3778\n",
      "Epoch [10/100], Loss: 2.2064\n",
      "Epoch [20/100], Loss: 0.8541\n",
      "Epoch [30/100], Loss: 0.5071\n",
      "Epoch [40/100], Loss: 0.4056\n",
      "Epoch [50/100], Loss: 0.2923\n",
      "Epoch [60/100], Loss: 0.2171\n",
      "Epoch [70/100], Loss: 0.1919\n",
      "Epoch [80/100], Loss: 0.2161\n",
      "Epoch [90/100], Loss: 0.1647\n",
      "Epoch [100/100], Loss: 0.1770\n",
      "Epoch [10/100], Loss: 2.6764\n",
      "Epoch [20/100], Loss: 0.8107\n",
      "Epoch [30/100], Loss: 0.4133\n",
      "Epoch [40/100], Loss: 0.2945\n",
      "Epoch [50/100], Loss: 0.3212\n",
      "Epoch [60/100], Loss: 0.2275\n",
      "Epoch [70/100], Loss: 0.1638\n",
      "Epoch [80/100], Loss: 0.1845\n",
      "Epoch [90/100], Loss: 0.1469\n",
      "Epoch [100/100], Loss: 0.1474\n",
      "Epoch [10/100], Loss: 2.5368\n",
      "Epoch [20/100], Loss: 1.2917\n",
      "Epoch [30/100], Loss: 0.9070\n",
      "Epoch [40/100], Loss: 0.5246\n",
      "Epoch [50/100], Loss: 0.3439\n",
      "Epoch [60/100], Loss: 0.3244\n",
      "Epoch [70/100], Loss: 0.2309\n",
      "Epoch [80/100], Loss: 0.1759\n",
      "Epoch [90/100], Loss: 0.1547\n",
      "Epoch [100/100], Loss: 0.1941\n",
      "Epoch [10/100], Loss: 1.7651\n",
      "Epoch [20/100], Loss: 0.6393\n",
      "Epoch [30/100], Loss: 0.4245\n",
      "Epoch [40/100], Loss: 0.2617\n",
      "Epoch [50/100], Loss: 0.2358\n",
      "Epoch [60/100], Loss: 0.1853\n",
      "Epoch [70/100], Loss: 0.1871\n",
      "Epoch [80/100], Loss: 0.1605\n",
      "Epoch [90/100], Loss: 0.1530\n",
      "Epoch [100/100], Loss: 0.1318\n",
      "Epoch [10/100], Loss: 2.0520\n",
      "Epoch [20/100], Loss: 0.7626\n",
      "Epoch [30/100], Loss: 0.4359\n",
      "Epoch [40/100], Loss: 0.3061\n",
      "Epoch [50/100], Loss: 0.2393\n",
      "Epoch [60/100], Loss: 0.1734\n",
      "Epoch [70/100], Loss: 0.1825\n",
      "Epoch [80/100], Loss: 0.1729\n",
      "Epoch [90/100], Loss: 0.1560\n",
      "Epoch [100/100], Loss: 0.1548\n",
      "Testing Linear...\n",
      "Testing Ridge...\n",
      "Testing RandomForest...\n",
      "Testing MLP...\n",
      "\n",
      "Benchmarking Diabetes dataset...\n",
      "Testing OIKAN...\n",
      "Epoch [10/100], Loss: 27592.9180\n",
      "Epoch [20/100], Loss: 24934.8516\n",
      "Epoch [30/100], Loss: 22203.4258\n",
      "Epoch [40/100], Loss: 19084.5488\n",
      "Epoch [50/100], Loss: 15644.6602\n",
      "Epoch [60/100], Loss: 12026.4102\n",
      "Epoch [70/100], Loss: 8853.9502\n",
      "Epoch [80/100], Loss: 6351.0156\n",
      "Epoch [90/100], Loss: 4708.5171\n",
      "Epoch [100/100], Loss: 2769.3838\n",
      "Epoch [10/100], Loss: 29094.5273\n",
      "Epoch [20/100], Loss: 27000.1562\n",
      "Epoch [30/100], Loss: 24587.2344\n",
      "Epoch [40/100], Loss: 21064.3613\n",
      "Epoch [50/100], Loss: 16917.5039\n",
      "Epoch [60/100], Loss: 12415.6299\n",
      "Epoch [70/100], Loss: 8378.6455\n",
      "Epoch [80/100], Loss: 4939.5962\n",
      "Epoch [90/100], Loss: 2594.3635\n",
      "Epoch [100/100], Loss: 2511.7236\n",
      "Epoch [10/100], Loss: 26776.5059\n",
      "Epoch [20/100], Loss: 25178.0684\n",
      "Epoch [30/100], Loss: 23235.0742\n",
      "Epoch [40/100], Loss: 20647.6953\n",
      "Epoch [50/100], Loss: 17681.2285\n",
      "Epoch [60/100], Loss: 14355.6992\n",
      "Epoch [70/100], Loss: 10732.7686\n",
      "Epoch [80/100], Loss: 6933.8931\n",
      "Epoch [90/100], Loss: 4057.3035\n",
      "Epoch [100/100], Loss: 2619.3313\n",
      "Epoch [10/100], Loss: 27026.2207\n",
      "Epoch [20/100], Loss: 25057.0586\n",
      "Epoch [30/100], Loss: 22435.9609\n",
      "Epoch [40/100], Loss: 18991.1641\n",
      "Epoch [50/100], Loss: 14975.9521\n",
      "Epoch [60/100], Loss: 11019.6074\n",
      "Epoch [70/100], Loss: 7221.3887\n",
      "Epoch [80/100], Loss: 4059.7888\n",
      "Epoch [90/100], Loss: 2381.5220\n",
      "Epoch [100/100], Loss: 2201.5032\n",
      "Epoch [10/100], Loss: 26429.8809\n",
      "Epoch [20/100], Loss: 23906.3027\n",
      "Epoch [30/100], Loss: 20357.7402\n",
      "Epoch [40/100], Loss: 16820.2559\n",
      "Epoch [50/100], Loss: 12572.7627\n",
      "Epoch [60/100], Loss: 8823.1162\n",
      "Epoch [70/100], Loss: 5367.1440\n",
      "Epoch [80/100], Loss: 2330.0117\n",
      "Epoch [90/100], Loss: 2681.0947\n",
      "Epoch [100/100], Loss: 2157.5459\n",
      "Epoch [10/100], Loss: 27613.3750\n",
      "Epoch [20/100], Loss: 26012.1309\n",
      "Epoch [30/100], Loss: 24168.1055\n",
      "Epoch [40/100], Loss: 21385.6934\n",
      "Epoch [50/100], Loss: 18676.1602\n",
      "Epoch [60/100], Loss: 14962.6934\n",
      "Epoch [70/100], Loss: 10279.3047\n",
      "Epoch [80/100], Loss: 6712.7021\n",
      "Epoch [90/100], Loss: 3611.2466\n",
      "Epoch [100/100], Loss: 2400.6658\n",
      "Testing Linear...\n",
      "Testing Ridge...\n",
      "Testing RandomForest...\n",
      "Testing MLP...\n",
      "\n",
      "Benchmarking Physics dataset...\n",
      "Testing OIKAN...\n",
      "Error benchmarking OIKAN: The size of tensor a (5) must match the size of tensor b (10) at non-singleton dimension 1\n",
      "Testing Linear...\n",
      "Testing Ridge...\n",
      "Testing RandomForest...\n",
      "Testing MLP...\n",
      "\n",
      "Benchmark Results Summary:\n",
      "==========================\n",
      "                                        MSE  Predict Time      R2  Train Time\n",
      "Dataset             Model                                                    \n",
      "Diabetes            Linear        2900.1936        0.0001  0.4526      0.0012\n",
      "                    MLP           3107.3307        0.0003  0.4135      0.6085\n",
      "                    OIKAN         3241.6551        0.1233  0.3882     39.6013\n",
      "                    RandomForest  3067.9353        0.0041  0.4209      0.2489\n",
      "                    Ridge         2892.0301        0.0001  0.4541      0.0009\n",
      "Linear Synthetic    Linear           0.0095        0.0003  1.0000      0.0235\n",
      "                    MLP             31.9799        0.0003  0.9981      1.1765\n",
      "                    OIKAN          456.8398        0.1335  0.9729     46.1741\n",
      "                    RandomForest  2619.2825        0.0056  0.8447      0.5041\n",
      "                    Ridge            0.0371        0.0002  1.0000      0.0136\n",
      "Nonlinear Synthetic Linear           3.9688        0.0002  0.2121      0.0022\n",
      "                    MLP              0.2877        0.0004  0.9429      1.2997\n",
      "                    OIKAN            0.3683        0.1242  0.9269     39.7682\n",
      "                    RandomForest     0.5076        0.0059  0.8992      0.6316\n",
      "                    Ridge            3.9690        0.0001  0.2120      0.0009\n",
      "Physics             Linear           0.0093        0.0001  1.0000      0.0012\n",
      "                    MLP              0.0186        0.0003  0.9999      0.4055\n",
      "                    RandomForest     0.0132        0.0055  0.9999      0.2586\n",
      "                    Ridge            0.0151        0.0001  0.9999      0.0008\n"
     ]
    }
   ],
   "source": [
    "# Initialize models\n",
    "models = {\n",
    "    'OIKAN': OIKANRegressor(hidden_dims=[32, 16]),\n",
    "    'Linear': LinearRegression(),\n",
    "    'Ridge': Ridge(alpha=1.0),\n",
    "    'RandomForest': RandomForestRegressor(n_estimators=100),\n",
    "    'MLP': MLPRegressor(hidden_layer_sizes=(32, 16), max_iter=500)\n",
    "}\n",
    "\n",
    "# Get datasets\n",
    "datasets = generate_datasets()\n",
    "results_list = []\n",
    "\n",
    "# Run benchmarks\n",
    "for dataset_name, (X, y) in datasets.items():\n",
    "    print(f\"\\nBenchmarking {dataset_name} dataset...\")\n",
    "    \n",
    "    for model_name, model in models.items():\n",
    "        print(f\"Testing {model_name}...\")\n",
    "        res = benchmark_model(model, X, y, model_name)\n",
    "        res['Dataset'] = dataset_name\n",
    "        results_list.append(res)\n",
    "\n",
    "# Convert results to DataFrame\n",
    "results_df = pd.DataFrame(results_list)\n",
    "\n",
    "# Display summary table\n",
    "summary = results_df.pivot_table(\n",
    "    index=['Dataset', 'Model'],\n",
    "    values=['R2', 'MSE', 'Train Time', 'Predict Time'],\n",
    "    aggfunc='mean'\n",
    ").round(4)\n",
    "\n",
    "print(\"\\nBenchmark Results Summary:\")\n",
    "print(\"==========================\")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0169338c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T21:16:23.777088Z",
     "iopub.status.busy": "2025-04-13T21:16:23.776680Z",
     "iopub.status.idle": "2025-04-13T21:16:23.806238Z",
     "shell.execute_reply": "2025-04-13T21:16:23.805440Z"
    },
    "papermill": {
     "duration": 0.057732,
     "end_time": "2025-04-13T21:16:23.807303",
     "exception": true,
     "start_time": "2025-04-13T21:16:23.749571",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'OIKANRegressor'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_19/1334300169.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Feature importance analysis for OIKAN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0moikan_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'OIKANRegressor'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'\\nFeature Importance Analysis for {dataset_name}:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'OIKANRegressor'"
     ]
    }
   ],
   "source": [
    "# Feature importance analysis for OIKAN\n",
    "oikan_model = models['OIKANRegressor']\n",
    "\n",
    "for dataset_name, (X, y) in datasets.items():\n",
    "    print(f'\\nFeature Importance Analysis for {dataset_name}:')\n",
    "    X_scaled = StandardScaler().fit_transform(X)\n",
    "    oikan_model.fit(X_scaled, y)\n",
    "    \n",
    "    feature_scores = oikan_model.get_feature_scores()\n",
    "    \n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.bar(range(len(feature_scores)), feature_scores)\n",
    "    plt.title(f'OIKAN Feature Importance - {dataset_name}')\n",
    "    plt.xlabel('Feature Index')\n",
    "    plt.ylabel('Importance Score')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 863.660966,
   "end_time": "2025-04-13T21:16:25.757228",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-13T21:02:02.096262",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
