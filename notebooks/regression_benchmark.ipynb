{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e1a2274",
   "metadata": {},
   "source": [
    "# OIKAN Regression Benchmark Tests\n",
    "\n",
    "This notebook evaluates the OIKANRegressor on various regression tasks to assess:\n",
    "1. Prediction Accuracy (MSE, R²)\n",
    "2. Training and Prediction Time\n",
    "3. Symbolic formula extraction and prediction quality\n",
    "\n",
    "## Dataset Types:\n",
    "1. Synthetic Dataset (make_regression)\n",
    "2. Real Datasets:\n",
    "   - Diabetes Dataset\n",
    "   - Weather Temperature Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122a4651",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "!pip install -qU oikan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10852ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip freeze | grep oikan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68000c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_regression, load_diabetes\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from oikan.model import OIKANRegressor\n",
    "\n",
    "np.random.seed(42)\n",
    "print('Libraries imported.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cbf06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic regression dataset\n",
    "def generate_regression_data(n_samples=1000, n_features=10, noise=10.0):\n",
    "    X, y = make_regression(n_samples=n_samples, n_features=n_features, noise=noise, random_state=42)\n",
    "    return X, y\n",
    "\n",
    "X, y = generate_regression_data()\n",
    "print(f'Dataset shape: X={X.shape}, y={y.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ff1955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets with consistent feature dimensions\n",
    "def load_weather_data():\n",
    "    rng = np.random.RandomState(42)\n",
    "    n_samples = 1000\n",
    "    n_features = 10  # Match feature dimension with other datasets\n",
    "    X = rng.randn(n_samples, n_features)\n",
    "    noise = 0.1\n",
    "    # Use first 4 features for the actual relationship\n",
    "    y = 3.0 * X[:, 0] + 2.0 * X[:, 1] - 1.5 * X[:, 2] + 0.5 * X[:, 3] + noise * rng.randn(n_samples)\n",
    "    return X, y\n",
    "\n",
    "def load_datasets():\n",
    "    try:\n",
    "        datasets = {\n",
    "            'Synthetic': make_regression(n_samples=1000, n_features=10, noise=10.0, random_state=42),\n",
    "            'Diabetes': load_diabetes(return_X_y=True),  # Already has 10 features\n",
    "            'Weather': load_weather_data()\n",
    "        }\n",
    "        return datasets\n",
    "    except Exception as e:\n",
    "        print(f'Error loading datasets: {str(e)}')\n",
    "        return {}\n",
    "\n",
    "print('Loading datasets...')\n",
    "datasets = load_datasets()\n",
    "if datasets:\n",
    "    for name, (X, y) in datasets.items():\n",
    "        print(f'{name} dataset shape: X={X.shape}, y={y.shape}')\n",
    "else:\n",
    "    print('Failed to load datasets!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbcfe84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_regressor(model, X, y, model_name='OIKANRegressor'):\n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Training\n",
    "    start_time = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    train_time = time.time() - start_time\n",
    "\n",
    "    # Neural Network Prediction\n",
    "    start_time = time.time()\n",
    "    y_pred = model.predict(X_test)\n",
    "    predict_time = time.time() - start_time\n",
    "\n",
    "    results = {\n",
    "        'Model': model_name,\n",
    "        'MSE': mean_squared_error(y_test, y_pred),\n",
    "        'R2': r2_score(y_test, y_pred),\n",
    "        'Train Time': train_time,\n",
    "        'Predict Time': predict_time\n",
    "    }\n",
    "\n",
    "    # For OIKAN, add symbolic prediction results\n",
    "    if model_name == 'OIKANRegressor':\n",
    "        # Get symbolic formula and predictions\n",
    "        symbolic_formula = model.get_symbolic_formula()\n",
    "        y_sym = model.symbolic_predict(X_test)\n",
    "        \n",
    "        # Calculate symbolic performance\n",
    "        results.update({\n",
    "            'Symbolic MSE': mean_squared_error(y_test, y_sym),\n",
    "            'Symbolic R2': r2_score(y_test, y_sym),\n",
    "            'Symbolic Formula': symbolic_formula\n",
    "        })\n",
    "\n",
    "    return results\n",
    "\n",
    "print('Benchmark function defined.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1193827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize models with consistent architectures\n",
    "models = {\n",
    "    'OIKANRegressor': OIKANRegressor(hidden_dims=[10, 5]),  # Match input dimension\n",
    "    'LinearRegression': LinearRegression(),\n",
    "    'RandomForestRegressor': RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    'MLPRegressor': MLPRegressor(hidden_layer_sizes=(10, 5), max_iter=500, random_state=42)\n",
    "}\n",
    "\n",
    "results_list = []\n",
    "\n",
    "for dataset_name, (X, y) in datasets.items():\n",
    "    print(f'\\nTesting on {dataset_name} dataset:')\n",
    "    for model_name, model in models.items():\n",
    "        print(f'Benchmarking {model_name}...')\n",
    "        res = benchmark_regressor(model, X, y, model_name=model_name)\n",
    "        res['Dataset'] = dataset_name\n",
    "        results_list.append(res)\n",
    "        \n",
    "        # Print results\n",
    "        print(f\"{model_name}:\")\n",
    "        print(f\"MSE={res.get('MSE', 'N/A'):.4f}, R2={res.get('R2', 'N/A'):.4f}\")\n",
    "        if model_name == 'OIKANRegressor':\n",
    "            print(f\"Symbolic MSE={res.get('Symbolic MSE', 'N/A'):.4f}\")\n",
    "            print(f\"Symbolic R2={res.get('Symbolic R2', 'N/A'):.4f}\")\n",
    "\n",
    "# Generate performance table\n",
    "df_results = pd.DataFrame(results_list)\n",
    "summary = df_results.pivot_table(\n",
    "    index=['Dataset', 'Model'],\n",
    "    values=['MSE', 'R2', 'Symbolic MSE', 'Symbolic R2'],\n",
    "    aggfunc='mean'\n",
    ").round(4)\n",
    "print('\\nRegression Benchmark Performance Table:')\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c506b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize results\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "# R² Score Comparison\n",
    "plt.subplot(121)\n",
    "sns.barplot(data=df_results, x='Dataset', y='R2', hue='Model')\n",
    "plt.title('R² Score by Model and Dataset')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "\n",
    "# MSE Comparison\n",
    "plt.subplot(122)\n",
    "sns.barplot(data=df_results, x='Dataset', y='MSE', hue='Model')\n",
    "plt.title('MSE by Model and Dataset')\n",
    "plt.xticks(rotation=45)\n",
    "plt.yscale('log')  # Use log scale for MSE\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7511365",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance analysis for OIKAN\n",
    "oikan_model = models['OIKANRegressor']\n",
    "\n",
    "for dataset_name, (X, y) in datasets.items():\n",
    "    print(f'\\nFeature Importance Analysis for {dataset_name}:')\n",
    "    X_scaled = StandardScaler().fit_transform(X)\n",
    "    oikan_model.fit(X_scaled, y)\n",
    "    \n",
    "    feature_scores = oikan_model.get_feature_scores()\n",
    "    \n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.bar(range(len(feature_scores)), feature_scores)\n",
    "    plt.title(f'OIKAN Feature Importance - {dataset_name}')\n",
    "    plt.xlabel('Feature Index')\n",
    "    plt.ylabel('Importance Score')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
